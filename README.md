# ğŸ¤ Voice Chat Demo with OpenAI API ğŸ¤–

A real-time voice chat demo built with Next.js, React, shadcn/ui, and Tailwind CSS. This app captures user voice, streams it to the OpenAI Whisper API for transcription, and displays AI responses from OpenAI GPT-4o as text in chat bubbles.

## âœ¨ Features
- ğŸ™ï¸ Real-time voice input (Web Audio API)
- ğŸ”„ Streaming AI responses from OpenAI GPT-4o
- ğŸ’ Modern UI with shadcn/ui and Tailwind CSS
- ğŸ’¬ Conversation history in chat bubbles
- â™¿ Accessible and responsive design

## ğŸ› ï¸ Tech Stack
- **Framework:** Next.js (React, TypeScript)
- **UI:** shadcn/ui, Tailwind CSS
- **API:** OpenAI Whisper (speech-to-text), OpenAI GPT-4o (chat completions)
- **Voice:** Web Audio API, MediaRecorder

## ğŸš€ Getting Started

### 1. ğŸ§‘â€ğŸ’» Clone the repository
```bash
git clone <your-repo-url>
cd voice-chat-demo
```

### 2. ğŸ“¦ Install dependencies
```bash
npm install
```

### 3. ğŸ”‘ Configure Environment Variables
Create a `.env.local` file in the project root:
```
NEXT_PUBLIC_OPENAI_API_KEY=your_openai_api_key_here
```

### 4. â–¶ï¸ Run the development server
```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) to view the app.

## ğŸ—‚ï¸ Project Structure
- `src/components/ui/chat-bubble.tsx` â€“ ğŸ’¬ Chat bubble UI component
- `src/components/chat-interface.tsx` â€“ ğŸ§  Main chat interface logic
- `src/lib/openai.ts` â€“ ğŸ”— OpenAI API utility
- `src/lib/utils.ts` â€“ ğŸ› ï¸ Utility functions
- `src/app/api/openai-transcribe/route.ts` â€“ ğŸ¤ Whisper API endpoint
- `src/app/api/openai-chat/route.ts` â€“ ğŸ¤– Chat completions endpoint
- `memory-bank/` â€“ ğŸ—ƒï¸ Project documentation and context

## ğŸ“„ License
This project is licensed under the MIT License. See [LICENSE](./LICENSE) for details.

---

This is a [Next.js](https://nextjs.org) project bootstrapped with [`create-next-app`](https://nextjs.org/docs/app/api-reference/cli/create-next-app).
